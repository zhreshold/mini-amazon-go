{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练你的物体检测器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gluoncv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gluoncv as gcv\n",
    "import mxnet as mx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 准备训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class DetectionDataset(gcv.data.VOCDetection):\n",
    "    CLASSES = ['cocacola', 'cocacola-zero', 'juice', 'noodles', 'hand']  # , 'cocacola-shadow', 'cocacola-zero-shadow', 'juice-shadow', 'noodles-shadow'\n",
    "    def __init__(self, root):\n",
    "        self._im_shapes = {}\n",
    "        self._root = os.path.expanduser(root)\n",
    "        self._transform = None\n",
    "        self._items = [(self._root, x.strip('.xml')) for x in os.listdir(self._root) if x.endswith('.xml')]\n",
    "        self._anno_path = os.path.join('{}', '{}.xml')\n",
    "        self._image_path = os.path.join('{}', '{}.jpg')\n",
    "        self.index_map = dict(zip(self.classes, range(self.num_class)))\n",
    "        self._label_cache = self._preload_labels()\n",
    "        \n",
    "    def __str__(self):\n",
    "        detail = self._root\n",
    "        return self.__class__.__name__ + '(' + detail + ')'\n",
    "    \n",
    "    @property\n",
    "    def classes(self):\n",
    "        return self.CLASSES\n",
    "    \n",
    "    @property\n",
    "    def num_class(self):\n",
    "        return len(self.classes)\n",
    "        \n",
    "train_dataset = DetectionDataset('../images/v2')\n",
    "print('class_names:', train_dataset.classes)\n",
    "print('num_images:', len(train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 可视化数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from gluoncv.utils import viz\n",
    "\n",
    "sample = train_dataset[0]\n",
    "train_image = sample[0]\n",
    "train_label = sample[1]\n",
    "\n",
    "ax = viz.plot_bbox(\n",
    "    train_image.asnumpy(),\n",
    "    train_label[:, :4],\n",
    "    labels=train_label[:, 4:5],\n",
    "    class_names=train_dataset.classes)\n",
    "plt.show()\n",
    "\n",
    "# for i in range(len(train_dataset)):\n",
    "#     sample = train_dataset[i]\n",
    "#     train_image = sample[0]\n",
    "#     train_label = sample[1]\n",
    "\n",
    "#     ax = viz.plot_bbox(\n",
    "#         train_image.asnumpy(),\n",
    "#         train_label[:, :4],\n",
    "#         labels=train_label[:, 4:5],\n",
    "#         class_names=train_dataset.classes)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "from mxnet import autograd\n",
    "from gluoncv.data.batchify import Tuple, Stack, Pad\n",
    "\n",
    "def train_model(train_dataset, epochs=50):\n",
    "    ctx = mx.gpu(0)\n",
    "#     ctx = mx.cpu(0)\n",
    "    net = gcv.model_zoo.get_model('ssd_512_resnet50_v1_custom', classes=train_dataset.classes, transfer='coco')\n",
    "#     net.load_parameters('object_detector_epoch200_10_22_2019_20_28_41.params')  # TODO continue training\n",
    "    net.collect_params().reset_ctx(ctx)\n",
    "    width, height = 512, 512  # suppose we use 512 as base training size\n",
    "    train_transform = gcv.data.transforms.presets.ssd.SSDDefaultTrainTransform(width, height)\n",
    "    gcv.utils.random.seed(233)\n",
    "    \n",
    "#     batch_size = 4\n",
    "    batch_size = 16  # 32 for p3.2xlarge, 16 for p2.2xlarge\n",
    "    # you can make it larger(if your CPU has more cores) to accelerate data loading\n",
    "    num_workers = 4\n",
    "\n",
    "    with autograd.train_mode():\n",
    "        _, _, anchors = net(mx.nd.zeros((1, 3, height, width), ctx))\n",
    "    anchors = anchors.as_in_context(mx.cpu())\n",
    "    train_transform = gcv.data.transforms.presets.ssd.SSDDefaultTrainTransform(width, height, anchors)\n",
    "    batchify_fn = Tuple(Stack(), Stack(), Stack())\n",
    "    train_loader = mx.gluon.data.DataLoader(\n",
    "        train_dataset.transform(train_transform),\n",
    "        batch_size,\n",
    "        shuffle=True,\n",
    "        batchify_fn=batchify_fn,\n",
    "        last_batch='rollover',\n",
    "        num_workers=num_workers)\n",
    "    \n",
    "    mbox_loss = gcv.loss.SSDMultiBoxLoss()\n",
    "    ce_metric = mx.metric.Loss('CrossEntropy')\n",
    "    smoothl1_metric = mx.metric.Loss('SmoothL1')\n",
    "    for k, v in net.collect_params().items():\n",
    "        if 'convpredictor' not in k:\n",
    "            # freeze upper layers\n",
    "            v.grad_req = 'null'\n",
    "    trainer = mx.gluon.Trainer(\n",
    "        net.collect_params(), 'sgd',\n",
    "        {'learning_rate': 0.001, 'wd': 0.0005, 'momentum': 0.9})\n",
    "    \n",
    "    net.hybridize(static_alloc=True, static_shape=True)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        tic = time.time()\n",
    "        btic = time.time()\n",
    "        \n",
    "        for i, batch in enumerate(train_loader):\n",
    "            data = mx.gluon.utils.split_and_load(batch[0], ctx_list=[ctx], batch_axis=0)\n",
    "            cls_targets = mx.gluon.utils.split_and_load(batch[1], ctx_list=[ctx], batch_axis=0)\n",
    "            box_targets = mx.gluon.utils.split_and_load(batch[2], ctx_list=[ctx], batch_axis=0)\n",
    "            \n",
    "            with autograd.record():\n",
    "                cls_preds = []\n",
    "                box_preds = []\n",
    "                for x in data:\n",
    "                    cls_pred, box_pred, _ = net(x)\n",
    "                    cls_preds.append(cls_pred)\n",
    "                    box_preds.append(box_pred)\n",
    "                sum_loss, cls_loss, box_loss = mbox_loss(\n",
    "                    cls_preds, box_preds, cls_targets, box_targets)\n",
    "                autograd.backward(sum_loss)\n",
    "            # since we have already normalized the loss, we don't want to normalize\n",
    "            # by batch-size anymore\n",
    "            trainer.step(1)\n",
    "            ce_metric.update(0, [l * batch_size for l in cls_loss])\n",
    "            smoothl1_metric.update(0, [l * batch_size for l in box_loss])\n",
    "            name1, loss1 = ce_metric.get()\n",
    "            name2, loss2 = smoothl1_metric.get()\n",
    "            print('[Epoch {}][Batch {}], Speed: {:.3f} samples/sec, {}={:.3f}, {}={:.3f}'.format(\n",
    "                epoch, i, batch_size/(time.time()-btic), name1, loss1, name2, loss2))\n",
    "            btic = time.time()\n",
    "    return net\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 300\n",
    "net = train_model(train_dataset, epochs=epochs)\n",
    "save_file = 'object_detector_epoch{}_{}.params'.format(epochs, datetime.now().strftime(\"%m_%d_%Y_%H_%M_%S\"))\n",
    "net.save_parameters(save_file)\n",
    "print('Saved model to disk: ' + save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
